"""
Test cases for LBO Model Generator
Uses AI-generated company data for realistic test scenarios.
"""

import json
import os
import sys
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from lbo_model_generator import create_lbo_from_inputs, LBOModel, LBOAssumptions, LBODebtStructure


def load_ai_test_company():
    """Load AI-generated test company configuration.

    Priority order:
    1. base_test_case.json (primary base test case generated by OpenAI)
    2. ai_test_company.json (legacy AI-generated test case)
    3. Default fallback configuration
    """
    # Try base test case first (primary)
    base_test_file = Path(__file__).parent / "base_test_case.json"
    if base_test_file.exists():
        with open(base_test_file, "r") as f:
            config = json.load(f)
        # Remove metadata for model creation
        config_clean = {k: v for k, v in config.items() if not k.startswith("_")}
        return config_clean, config.get("company_name", "Base Test Company")

    # Fallback to legacy AI test company
    test_file = Path(__file__).parent / "ai_test_company.json"
    if test_file.exists():
        with open(test_file, "r") as f:
            config = json.load(f)
        # Remove metadata for model creation
        config_clean = {k: v for k, v in config.items() if not k.startswith("_")}
        return config_clean, config.get("company_name", "AI Test Company")

    # Final fallback to default
    return get_default_test_config(), "Default Test Company"


def get_default_test_config():
    """Fallback default configuration if AI company file not available."""
    return {
        "entry_ebitda": 10000,
        "entry_multiple": 6.5,
        "existing_debt": 0,
        "existing_cash": 500,
        "transaction_expenses_pct": 0.03,
        "financing_fees_pct": 0.02,
        "revenue_growth_rate": [0.05, 0.05, 0.05, 0.05, 0.05],
        "debt_instruments": [
            {
                "name": "Senior Debt",
                "interest_rate": 0.08,
                "ebitda_multiple": 1.0,
                "amortization_schedule": "amortizing",
                "amortization_periods": 5,
            },
            {
                "name": "Subordinated Debt",
                "interest_rate": 0.12,
                "ebitda_multiple": 2.0,
                "amortization_schedule": "bullet",
            },
        ],
        "cogs_pct_of_revenue": 0.70,
        "sganda_pct_of_revenue": 0.15,
        "capex_pct_of_revenue": 0.03,
        "tax_rate": 0.25,
        "days_sales_outstanding": 45.0,
        "days_inventory_outstanding": 30.0,
        "days_payable_outstanding": 30.0,
        "exit_year": 5,
        "exit_multiple": 7.5,
        "starting_revenue": 50000,
    }


def test_basic_lbo_model():
    """Test basic LBO model generation using AI-generated company."""
    print("=" * 80)
    print("TEST 1: Basic LBO Model Generation (AI-Generated Company)")
    print("=" * 80)

    # Load AI-generated test company
    test_config, company_name = load_ai_test_company()
    print(f"Company: {company_name}")
    print(f"Entry EBITDA: ${test_config.get('entry_ebitda', 0):,.0f}")
    print(f"Entry Multiple: {test_config.get('entry_multiple', 0):.1f}x")
    print()

    try:
        model = create_lbo_from_inputs(test_config)

        # Test financial statements
        assert len(model.income_statement) > 0, "Income statement should have rows"
        assert len(model.balance_sheet) > 0, "Balance sheet should have rows"
        assert len(model.cash_flow) > 0, "Cash flow should have rows"

        # Test that Year 5 EBITDA exists
        year5_ebitda = model.income_statement.loc["EBITDA", 5]
        assert year5_ebitda > 0, f"Year 5 EBITDA should be positive, got {year5_ebitda}"

        # Test returns calculation
        returns = model.calculate_returns()
        assert returns["exit_ebitda"] > 0, "Exit EBITDA should be positive"
        assert returns["exit_ev"] > 0, "Exit EV should be positive"
        assert returns["moic"] > 0, "MOIC should be positive"
        assert not (returns["irr"] != returns["irr"]), "IRR should not be NaN"  # NaN check

        # Test Excel export with company name
        output_file = "test_output_basic.xlsx"
        model.export_to_excel(output_file, company_name=company_name)
        assert os.path.exists(output_file), f"Output file {output_file} should exist"

        print("âœ“ All basic model tests passed!")
        print(f"  - Company: {company_name}")
        print(f"  - Income Statement: {len(model.income_statement)} rows")
        print(f"  - Balance Sheet: {len(model.balance_sheet)} rows")
        print(f"  - Cash Flow: {len(model.cash_flow)} rows")
        print(f"  - Year 5 EBITDA: ${year5_ebitda:,.0f}")
        print(f"  - Exit Equity Value: ${returns['exit_equity_value']:,.0f}")
        print(f"  - MOIC: {returns['moic']:.2f}x")
        # IRR is returned as decimal (e.g., 0.24), convert to percentage for display
        irr_pct = returns["irr"] * 100 if returns["irr"] < 1 else returns["irr"]
        print(f"  - IRR: {irr_pct:.2f}%")
        print(f"  - Excel file created: {output_file}")

        return True

    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_balance_sheet_balancing():
    """Test that balance sheets balance using AI-generated company."""
    print("\n" + "=" * 80)
    print("TEST 2: Balance Sheet Balancing (AI-Generated Company)")
    print("=" * 80)

    # Use AI-generated company config (simplified for this test)
    test_config, company_name = load_ai_test_company()
    # Use only essential fields for balance sheet test
    test_config = {
        "entry_ebitda": test_config.get("entry_ebitda", 7000),
        "entry_multiple": test_config.get("entry_multiple", 6.0),
        "revenue_growth_rate": test_config.get(
            "revenue_growth_rate", [0.15, 0.12, 0.10, 0.08, 0.07]
        ),
        "debt_instruments": test_config.get("debt_instruments", []),
        "starting_revenue": test_config.get("starting_revenue", 35000),
        "existing_debt": test_config.get("existing_debt", 0),
        "existing_cash": test_config.get("existing_cash", 1000),
    }
    print(f"Company: {company_name}")

    try:
        model = create_lbo_from_inputs(test_config)

        # Check all years balance
        all_balance = True
        for year in model.years:
            assets = model.balance_sheet.loc["Total Assets", year]
            liab_eq = model.balance_sheet.loc["Total Liabilities & Equity", year]
            diff = abs(assets - liab_eq)

            if diff > 1.0:  # Allow small rounding differences
                print(
                    f"  âš ï¸  Year {year}: Assets = ${assets:,.2f}, Liab+EQ = ${liab_eq:,.2f}, Diff = ${diff:,.2f}"
                )
                all_balance = False

        if all_balance:
            print("âœ“ Balance sheets balance for all years")
            return True
        else:
            print("âœ— Some balance sheets do not balance")
            return False

    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_cash_flow_reconciliation():
    """Test cash flow statement reconciliation using AI-generated company."""
    print("\n" + "=" * 80)
    print("TEST 3: Cash Flow Reconciliation (AI-Generated Company)")
    print("=" * 80)

    # Use AI-generated company config (full config for proper cash flow reconciliation)
    test_config, company_name = load_ai_test_company()
    print(f"Company: {company_name}")

    try:
        model = create_lbo_from_inputs(test_config)

        all_reconcile = True
        for i, year in enumerate(model.years):
            if i == 0:
                continue  # Skip first year

            # Check that ending cash of previous year = beginning cash of current year
            prev_ending = model.cash_flow.loc["Ending Cash Balance", year - 1]
            curr_beginning = model.cash_flow.loc["Beginning Cash Balance", year]
            diff = abs(prev_ending - curr_beginning)

            if diff > 0.01:
                print(
                    f"  âš ï¸  Year {year}: Previous ending (${prev_ending:,.2f}) != Current beginning (${curr_beginning:,.2f})"
                )
                all_reconcile = False

            # Check that beginning + net change = ending
            beginning = model.cash_flow.loc["Beginning Cash Balance", year]
            net_change = model.cash_flow.loc["Net Change in Cash", year]
            ending = model.cash_flow.loc["Ending Cash Balance", year]
            calc_ending = beginning + net_change

            if abs(calc_ending - ending) > 0.01:
                print(f"  âš ï¸  Year {year}: Beginning + Net Change != Ending")
                all_reconcile = False

        if all_reconcile:
            print("âœ“ Cash flow reconciles properly")
            return True
        else:
            print("âœ— Cash flow reconciliation issues")
            return False

    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_debt_schedule():
    """Test debt schedule calculations using AI-generated company."""
    print("\n" + "=" * 80)
    print("TEST 4: Debt Schedule (AI-Generated Company)")
    print("=" * 80)

    # Use AI-generated company config
    test_config, company_name = load_ai_test_company()
    print(f"Company: {company_name}")
    print(f"Debt Instruments: {len(test_config.get('debt_instruments', []))}")

    # Ensure we have the debt instruments from AI config
    if not test_config.get("debt_instruments"):
        # Fallback if no debt instruments
        test_config["debt_instruments"] = [
            {
                "name": "Senior Debt",
                "interest_rate": 0.07,
                "ebitda_multiple": 1.5,
                "amortization_schedule": "amortizing",
                "amortization_periods": 5,
            },
            {
                "name": "Subordinated Debt",
                "interest_rate": 0.11,
                "ebitda_multiple": 2.0,
                "amortization_schedule": "bullet",
            },
        ]

    try:
        model = create_lbo_from_inputs(test_config)

        # Check that senior debt amortizes
        senior_debt_name = test_config["debt_instruments"][0]["name"]
        senior_debt_year1 = model.debt_schedule[senior_debt_name]["ending_balance"][0]
        senior_debt_year5 = model.debt_schedule[senior_debt_name]["ending_balance"][4]

        assert senior_debt_year1 > senior_debt_year5, "Senior debt should amortize"

        # Check that sub debt stays constant (bullet) if present
        if len(test_config["debt_instruments"]) > 1:
            sub_debt_name = test_config["debt_instruments"][1]["name"]
            sub_debt_year1 = model.debt_schedule[sub_debt_name]["ending_balance"][0]
            sub_debt_year4 = model.debt_schedule[sub_debt_name]["ending_balance"][3]
            sub_debt_year5 = model.debt_schedule[sub_debt_name]["ending_balance"][4]

            assert abs(sub_debt_year1 - sub_debt_year4) < 0.01, "Sub debt should remain constant"
            assert sub_debt_year5 == 0, "Sub debt should be repaid in final year (bullet)"

            print("âœ“ Debt schedule calculations correct")
            print(f"  - {senior_debt_name} Year 1: ${senior_debt_year1:,.0f}")
            print(f"  - {senior_debt_name} Year 5: ${senior_debt_year5:,.0f}")
            print(f"  - {sub_debt_name} (bullet, Year 1-4): ${sub_debt_year1:,.0f}")
            print(f"  - {sub_debt_name} Year 5: ${sub_debt_year5:,.0f}")
        else:
            print("âœ“ Debt schedule calculations correct")
            print(f"  - {senior_debt_name} Year 1: ${senior_debt_year1:,.0f}")
            print(f"  - {senior_debt_name} Year 5: ${senior_debt_year5:,.0f}")

        return True

    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def test_ai_recommendations():
    """Test AI recommendations (if API key available)."""
    print("\n" + "=" * 80)
    print("TEST 5: AI Recommendations")
    print("=" * 80)

    try:
        # Import already handled at top of file
        from lbo_ai_recommender import LBOModelAIRecommender

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âš ï¸  Skipping AI test: OPENAI_API_KEY not set")
            print("   To test AI, set: export OPENAI_API_KEY='your-key'")
            return None

        recommender = LBOModelAIRecommender()

        # Use base test case (primary) or fallback to legacy
        test_config, company_name = load_ai_test_company()

        # Load full config for business description and industry
        base_test_file = Path(__file__).parent / "base_test_case.json"
        if base_test_file.exists():
            full_config = json.load(open(base_test_file, "r"))
        else:
            # Fallback to legacy file
            full_config = json.load(open(Path(__file__).parent / "ai_test_company.json", "r"))

        business_description = full_config.get("business_description", "")
        industry = full_config.get("industry", "Unknown")

        print(f"ðŸ”„ Getting AI recommendations for {company_name}...")
        print(f"   Industry: {industry}")
        recommendations = recommender.recommend_parameters(
            business_description,
            current_revenue=full_config.get("current_revenue", 35_000_000),
            current_ebitda=full_config.get("current_ebitda", 7_000_000),
            industry=industry,
        )

        # Validate recommendations
        assert recommendations.get("entry_ebitda") > 0, "Entry EBITDA should be positive"
        assert recommendations.get("entry_multiple") > 0, "Entry multiple should be positive"
        assert len(recommendations.get("revenue_growth_rate", [])) > 0, "Should have growth rates"
        assert (
            len(recommendations.get("debt_instruments", [])) > 0
        ), "Should have debt recommendations"

        print("âœ“ AI recommendations received")
        print(recommender.explain_recommendations(recommendations))

        # Test that recommendations can be used to create a model
        print("\nðŸ”„ Testing model generation from AI recommendations...")
        model = create_lbo_from_inputs(recommendations)
        returns = model.calculate_returns()

        print("âœ“ Model generated successfully from AI recommendations")
        print(f"  - MOIC: {returns['moic']:.2f}x")
        # IRR is returned as decimal (e.g., 0.24), convert to percentage for display
        irr_pct = returns["irr"] * 100 if returns["irr"] < 1 else returns["irr"]
        print(f"  - IRR: {irr_pct:.2f}%")

        return True

    except ImportError:
        print("âš ï¸  Skipping AI test: openai package not installed")
        print("   Install with: pip install openai")
        return None
    except Exception as e:
        print(f"âœ— AI test failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """Run all test cases."""
    print("\n" + "=" * 80)
    print("LBO MODEL GENERATOR - TEST SUITE")
    print("=" * 80)

    results = []

    # Run tests
    results.append(("Basic LBO Model", test_basic_lbo_model()))
    results.append(("Balance Sheet Balancing", test_balance_sheet_balancing()))
    results.append(("Cash Flow Reconciliation", test_cash_flow_reconciliation()))
    results.append(("Debt Schedule", test_debt_schedule()))
    ai_result = test_ai_recommendations()
    if ai_result is not None:
        results.append(("AI Recommendations", ai_result))

    # Summary
    print("\n" + "=" * 80)
    print("TEST SUMMARY")
    print("=" * 80)

    passed = sum(1 for _, result in results if result is True)
    failed = sum(1 for _, result in results if result is False)
    skipped = sum(1 for _, result in results if result is None)

    for test_name, result in results:
        if result is True:
            status = "âœ“ PASSED"
        elif result is False:
            status = "âœ— FAILED"
        else:
            status = "âš  SKIPPED"
        print(f"  {test_name:.<50} {status}")

    print("\n" + "-" * 80)
    print(f"Total: {len(results)} tests | Passed: {passed} | Failed: {failed} | Skipped: {skipped}")
    print("=" * 80)

    if failed > 0:
        sys.exit(1)
    else:
        print("\nâœ“ All tests passed!")
        sys.exit(0)


if __name__ == "__main__":
    main()
